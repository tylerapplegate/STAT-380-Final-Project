---
title: "STAT 380 Final Project Model Building"
author: "Tyler Applegate"
output: html_notebook
---

## Load in libraries.
```{r}
library(data.table)
library(Rtsne)
library(ggplot2)
library(caret)
library(ClusterR)
library(Metrics)
library(xgboost)
```

## Read in data.
```{r}
test<-fread("./project/volume/data/raw/test_file.csv")
train<-fread("./project/volume/data/raw/training_data.csv")
test_emb<-fread("./project/volume/data/raw/test_emb.csv")
train_emb<-fread("./project/volume/data/raw/training_emb.csv")
example_sub<-fread('./project/volume/data/raw/example_sub.csv')
master<-fread('./project/volume/data/interim/master_data.csv')
```

### Hide information. ###
```{r}
master$id<-NULL
master$reddit<-NULL
master$redditInt<-NULL
master$train<-NULL
```

###############
## Perform PCA.
###############
```{r}
pca<-prcomp(master)
```

## Look at the percent variance explained by each PCA.
```{r}
screeplot(pca)
```

## Look at the rotation of the variables on the PCs.
```{r}
pca
```

## See the values of the scree plot in a table.
```{r}
summary(pca)
```

## See a biplot of the first 2 PCs.
```{r}
biplot(pca)
```

## Use the unclass() function to get the data in PCA space.
```{r}
pca_dt<-data.table(unclass(pca)$x)
```

## Add back reddit and train information to graph.
```{r}
master<-fread('./project/volume/data/interim/master_data.csv')
pca_dt$reddit<-master$reddit
pca_dt$train<-master$train
sub_pcaDT<-pca_dt[train==1]
ggplot(sub_pcaDT,aes(x=PC1,y=PC2,col=reddit))+geom_point()
```

#################
## Perform t-SNE.
#################

## Remove information from pca_dt.
```{r}
pca_dt$reddit<-NULL
pca_dt$train<-NULL
```

## Run t-SNE on the PCA's.
```{r}
tsne<-Rtsne(pca_dt,pca = F,perplexity=25,check_duplicates = F)
```

## Grab out the coordinates.
```{r}
tsne_dt<-data.table(tsne$Y)
```

## Add back information columns to grpah.
```{r}
tsne_dt$reddit<-master$reddit
tsne_dt$id<-master$id
tsne_dt$train<-master$train
tsne_dt$redditInt<-master$redditInt
```

## Plot train data to see groupings.
```{r}
sub_tsneDTtrain<-tsne_dt[train==1]
sub_tsneDTtest<-tsne_dt[train==0][sample(1:nrow(tsne_dt),4000),]

sub_tsneDT<-rbind(sub_tsneDTtrain,sub_tsneDTtest)

ggplot(sub_tsneDT,aes(x=V1,y=V2,col=reddit))+geom_point()
```

###################
## Perform xgboost.
###################

## Split into train and test.
```{r}
train<-tsne_dt[train==1]
test<-tsne_dt[train==0]

y.train<-train$redditInt
y.test<-test$redditInt
```

## Remove information columns.
```{r}
train<-train[, -c("id","train","reddit")]
test<-test[, -c("id","train","reddit")]
```

## Work with dummies.
```{r}
dummies <- dummyVars(redditInt~ ., data = train)
x.train<-predict(dummies, newdata = train)
x.test<-predict(dummies, newdata = test)

dtrain <- xgb.DMatrix(x.train,label=(y.train),missing=NA)
dtest <- xgb.DMatrix(x.test,missing=NA)

hyper_perm_tune<-NULL
```

############################
## Perform cross validation.
############################
```{r}
param <- list(  objective           = "multi:softprob",
                num_class           = 10,
                gamma               = .01,
                booster             = "gbtree",
                eval_metric         = "mlogloss",
                eta                 = .01,
                max_depth           = 10,
                min_child_weight    = 5,
                subsample           = .99,
                colsample_bytree    = 1.0,
                tree_method = 'hist'
)


XGBm<-xgb.cv( params=param,nfold=200,nrounds=100000,missing=NA,data=dtrain,print_every_n=50,early_stopping_rounds=25)

best_ntrees<-unclass(XGBm)$best_iteration

new_row<-data.table(t(param))

new_row$best_ntrees<-best_ntrees

test_error<-unclass(XGBm)$evaluation_log[best_ntrees,]$test_mlogloss_mean

new_row$test_error<-test_error

hyper_perm_tune<-rbind(new_row,hyper_perm_tune)
```

####################################
## Fit the model to all of the data.
####################################
```{r}
watchlist <- list( train = dtrain)
```

## Fit the full model.
```{r}
XGBm<-xgb.train( params=param,nrounds=best_ntrees,missing=NA,data=dtrain,watchlist=watchlist,print_every_n=50)
```

## Use the predict function to get predictions from the model object.
```{r}
pred<-predict(XGBm, newdata = dtest)
```

##########################
## Make a submission file.
##########################

## Reformat predictions.
```{r}
results<-matrix(pred,ncol=10,byrow=T)
results<-data.table(results)

results$id<-example_sub$id
setnames(results, c("V1","V2","V3","V4","V5","V6","V7","V8","V9","V10"), c("subredditcars","subredditCooking","subredditMachineLearning","subredditmagicTCG","subredditpolitics","subredditReal_Estate","subredditscience","subredditStockMarket","subreddittravel","subredditvideogames"))

setcolorder(results, c("id"))

fwrite(results,"./project/volume/data/processed/finalResults.csv")
results[1:10]
```
